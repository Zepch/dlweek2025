{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from newsapi import NewsApiClient\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class MarketSentimentAnalyzer:\n",
    "    def __init__(self, news_api_key):\n",
    "        self.newsapi = NewsApiClient(api_key=news_api_key)\n",
    "        \n",
    "    def get_sentiment_scores(self, symbol, end_date, lookback_days=30):\n",
    "        \"\"\"\n",
    "        Get sentiment scores for the last 30 days\n",
    "        \n",
    "        Args:\n",
    "            symbol (str): Stock symbol\n",
    "            end_date (datetime): End date\n",
    "            lookback_days (int): Number of days to look back (default: 30)\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame: Daily sentiment scores\n",
    "        \"\"\"\n",
    "        # Calculate start date as 30 days before end date\n",
    "        start_date = end_date - timedelta(days=lookback_days)\n",
    "        \n",
    "        # Convert dates to string format\n",
    "        start_str = start_date.strftime('%Y-%m-%d')\n",
    "        end_str = end_date.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Get news articles\n",
    "        articles = self.newsapi.get_everything(\n",
    "            q=symbol,\n",
    "            from_param=start_str,\n",
    "            to=end_str,\n",
    "            language='en',\n",
    "            sort_by='publishedAt'\n",
    "        )\n",
    "        \n",
    "        # Process daily sentiment\n",
    "        daily_sentiment = {}\n",
    "        for article in articles['articles']:\n",
    "            date = article['publishedAt'][:10]\n",
    "            text = article['title'] + ' ' + article['description']\n",
    "            blob = TextBlob(text)\n",
    "            \n",
    "            if date not in daily_sentiment:\n",
    "                daily_sentiment[date] = []\n",
    "            daily_sentiment[date].append(blob.sentiment.polarity)\n",
    "        \n",
    "        # Average daily sentiments\n",
    "        sentiment_df = pd.DataFrame([\n",
    "            {'Date': date, 'Sentiment': np.mean(scores)}\n",
    "            for date, scores in daily_sentiment.items()\n",
    "        ])\n",
    "        sentiment_df['Date'] = pd.to_datetime(sentiment_df['Date'])\n",
    "        sentiment_df.set_index('Date', inplace=True)\n",
    "        \n",
    "        return sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class AdvancedStockDataset(Dataset):\n",
    "    def __init__(self, X_market, X_sentiment, y_price, y_direction, y_volatility):\n",
    "        self.X_market = torch.FloatTensor(X_market)\n",
    "        self.X_sentiment = torch.FloatTensor(X_sentiment)\n",
    "        self.y_price = torch.FloatTensor(y_price)\n",
    "        self.y_direction = torch.LongTensor(y_direction)\n",
    "        self.y_volatility = torch.FloatTensor(y_volatility)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X_market)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X_market[idx], self.X_sentiment[idx], \n",
    "                self.y_price[idx], self.y_direction[idx], self.y_volatility[idx])\n",
    "\n",
    "class AdvancedLSTMPredictor(nn.Module):\n",
    "    def __init__(self, market_dim, hidden_dim, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Market data LSTM\n",
    "        self.market_lstm = nn.LSTM(market_dim, hidden_dim, num_layers,\n",
    "                                batch_first=True, dropout=dropout)\n",
    "        \n",
    "        # Output heads\n",
    "        self.price_head = nn.Linear(hidden_dim, 1)\n",
    "        self.direction_head = nn.Linear(hidden_dim, 2)\n",
    "        self.volatility_head = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x_market):\n",
    "        # Process market data\n",
    "        market_out, _ = self.market_lstm(x_market)\n",
    "        features = market_out[:, -1, :]  # Get the last hidden state\n",
    "        \n",
    "        # Generate predictions directly from market features\n",
    "        price_pred = self.price_head(features)\n",
    "        direction_pred = self.direction_head(features)\n",
    "        volatility_pred = self.volatility_head(features)\n",
    "        \n",
    "        return price_pred, direction_pred, volatility_pred\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def prepare_market_data(df_market):\n",
    "    \"\"\"\n",
    "    Prepare market data for training using all available features and all timeframes\n",
    "    \n",
    "    Args:\n",
    "        df_market (pd.DataFrame): Market data with technical indicators\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (X_data, y_price, y_direction, y_volatility, scaler)\n",
    "    \"\"\"\n",
    "    # Get all available features\n",
    "    features = df_market.columns.tolist()\n",
    "    \n",
    "    # Handle any NaN values\n",
    "    df_market = df_market.fillna(0)\n",
    "    \n",
    "    # Scale all features\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(df_market)\n",
    "    \n",
    "    # Convert to tensor format\n",
    "    X_data = torch.FloatTensor(scaled_data[:-1])  # All data except last row\n",
    "    \n",
    "    # Price target (next day's close price)\n",
    "    close_idx = features.index('Close')\n",
    "    y_price = torch.FloatTensor(scaled_data[1:, close_idx])  # Shifted by 1 day\n",
    "    \n",
    "    # Direction target (1 if price went up, 0 if down)\n",
    "    price_directions = (scaled_data[1:, close_idx] > scaled_data[:-1, close_idx]).astype(int)\n",
    "    y_direction = torch.LongTensor(price_directions)\n",
    "    \n",
    "    # Volatility target (using rolling standard deviation of returns)\n",
    "    returns = np.diff(scaled_data[:, close_idx]) / scaled_data[:-1, close_idx]\n",
    "    volatility = np.std(returns) * np.sqrt(252)  # Annualized volatility\n",
    "    y_volatility = torch.FloatTensor([volatility] * len(y_price))\n",
    "    \n",
    "    return X_data, y_price, y_direction, y_volatility, scaler\n",
    "\n",
    "\n",
    "class CustomLoss:\n",
    "    def __init__(self, price_weight=1.0, direction_weight=0.3, volatility_weight=0.2):\n",
    "        self.price_criterion = nn.MSELoss()\n",
    "        self.direction_criterion = nn.CrossEntropyLoss()\n",
    "        self.volatility_criterion = nn.MSELoss()\n",
    "        \n",
    "        self.price_weight = price_weight\n",
    "        self.direction_weight = direction_weight\n",
    "        self.volatility_weight = volatility_weight\n",
    "    \n",
    "    def __call__(self, predictions, targets):\n",
    "        price_pred, direction_pred, volatility_pred = predictions\n",
    "        price_true, direction_true, volatility_true = targets\n",
    "        \n",
    "        price_loss = self.price_criterion(price_pred, price_true.unsqueeze(1))\n",
    "        direction_loss = self.direction_criterion(direction_pred, direction_true)\n",
    "        volatility_loss = self.volatility_criterion(volatility_pred, volatility_true.unsqueeze(1))\n",
    "        \n",
    "        return (self.price_weight * price_loss +\n",
    "                self.direction_weight * direction_loss +\n",
    "                self.volatility_weight * volatility_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ta.trend import MACD\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.volatility import BollingerBands\n",
    "\n",
    "def get_stock_data(ticker, period='2y'):\n",
    "    \"\"\"\n",
    "    Fetch historical stock data using yfinance\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): Stock ticker symbol\n",
    "        period (str): Time period to fetch (default: '2y')\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Historical OHLCV data\n",
    "    \"\"\"\n",
    "    stock = yf.Ticker(ticker)\n",
    "    df = stock.history(period=period)\n",
    "    return df\n",
    "\n",
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Create technical indicators as features\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): OHLCV DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with additional technical indicators\n",
    "    \"\"\"\n",
    "    # Moving averages\n",
    "    df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['SMA_50'] = df['Close'].rolling(window=50).mean()\n",
    "    \n",
    "    # RSI\n",
    "    rsi = RSIIndicator(df['Close'])\n",
    "    df['RSI'] = rsi.rsi()\n",
    "    \n",
    "    # MACD\n",
    "    macd = MACD(df['Close'])\n",
    "    df['MACD'] = macd.macd()\n",
    "    df['MACD_signal'] = macd.macd_signal()\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    bb = BollingerBands(df['Close'])\n",
    "    df['BB_upper'] = bb.bollinger_hband()\n",
    "    df['BB_lower'] = bb.bollinger_lband()\n",
    "    \n",
    "    # Percentage changes\n",
    "    df['Returns'] = df['Close'].pct_change()\n",
    "    df['Volatility'] = df['Returns'].rolling(window=20).std()\n",
    "    \n",
    "    # Remove NaN values\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize sentiment analyzer\n",
    "sentiment_analyzer = MarketSentimentAnalyzer(news_api_key='6dc6bc012b824525afa5969ae097f460')\n",
    "\n",
    "# Get market data\n",
    "df_market = get_stock_data('AAPL', period='5y')\n",
    "df_market = create_features(df_market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Open        High         Low       Close  \\\n",
      "Date                                                                        \n",
      "2025-02-24 00:00:00-05:00  244.929993  248.860001  244.419998  247.100006   \n",
      "2025-02-25 00:00:00-05:00  248.000000  250.000000  244.910004  247.039993   \n",
      "2025-02-26 00:00:00-05:00  244.330002  244.979996  239.130005  240.360001   \n",
      "2025-02-27 00:00:00-05:00  239.410004  242.460007  237.059998  237.300003   \n",
      "2025-02-28 00:00:00-05:00  236.949997  242.089996  230.199997  241.839996   \n",
      "\n",
      "                             Volume  Dividends  Stock Splits      SMA_20  \\\n",
      "Date                                                                       \n",
      "2025-02-24 00:00:00-05:00  51326400        0.0           0.0  237.186266   \n",
      "2025-02-25 00:00:00-05:00  48013300        0.0           0.0  238.057889   \n",
      "2025-02-26 00:00:00-05:00  44433600        0.0           0.0  238.175973   \n",
      "2025-02-27 00:00:00-05:00  41153600        0.0           0.0  238.086117   \n",
      "2025-02-28 00:00:00-05:00  56796200        0.0           0.0  238.311664   \n",
      "\n",
      "                               SMA_50        RSI      MACD  MACD_signal  \\\n",
      "Date                                                                      \n",
      "2025-02-24 00:00:00-05:00  240.485810  63.021918  2.668686     0.824240   \n",
      "2025-02-25 00:00:00-05:00  240.476652  62.907121  2.931394     1.245671   \n",
      "2025-02-26 00:00:00-05:00  240.359467  51.632935  2.570937     1.510724   \n",
      "2025-02-27 00:00:00-05:00  240.151713  47.438743  2.015127     1.611605   \n",
      "2025-02-28 00:00:00-05:00  240.031363  53.476956  1.918863     1.673056   \n",
      "\n",
      "                             BB_upper    BB_lower   Returns  Volatility  \n",
      "Date                                                                     \n",
      "2025-02-24 00:00:00-05:00  250.253319  224.119213  0.006312    0.016984  \n",
      "2025-02-25 00:00:00-05:00  251.310841  224.804936 -0.000243    0.015835  \n",
      "2025-02-26 00:00:00-05:00  251.466729  224.885216 -0.027040    0.015285  \n",
      "2025-02-27 00:00:00-05:00  251.375047  224.797186 -0.012731    0.015536  \n",
      "2025-02-28 00:00:00-05:00  251.694335  224.928993  0.019132    0.016019  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits',\n",
      "       'SMA_20', 'SMA_50', 'RSI', 'MACD', 'MACD_signal', 'BB_upper',\n",
      "       'BB_lower', 'Returns', 'Volatility'],\n",
      "      dtype='object')\n",
      "1208\n"
     ]
    }
   ],
   "source": [
    "print(df_market.tail())\n",
    "print(df_market.columns)\n",
    "print(len(df_market))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sentiment data\n",
    "end_date = df_market.index[-1]\n",
    "df_sentiment = sentiment_analyzer.get_sentiment_scores(\n",
    "    'AAPL',\n",
    "    end_date,\n",
    "    lookback_days=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Sentiment\n",
      "Date                 \n",
      "2025-02-28   0.192020\n",
      "2025-02-27   0.110859\n",
      "2025-02-26   0.141383\n",
      "2025-02-25   0.142170\n",
      "2025-02-24   0.099883\n"
     ]
    }
   ],
   "source": [
    "print(df_sentiment.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6518/2213265227.py:81: RuntimeWarning: divide by zero encountered in divide\n",
      "  returns = np.diff(scaled_data[:, close_idx]) / scaled_data[:-1, close_idx]\n",
      "/home/rey/anaconda3/envs/ml/lib/python3.10/site-packages/numpy/core/_methods.py:173: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the datasets\n",
    "X, y_price, y_direction, y_volatility, scaler = prepare_market_data(df_market)\n",
    "\n",
    "# Split into train/test sets\n",
    "train_size = int(len(X) * 0.8)\n",
    "\n",
    "X_train = X[:train_size]\n",
    "y_price_train = y_price[:train_size]\n",
    "y_direction_train = y_direction[:train_size]\n",
    "y_volatility_train = y_volatility[:train_size]\n",
    "\n",
    "X_test = X[train_size:]\n",
    "y_price_test = y_price[train_size:]\n",
    "y_direction_test = y_direction[train_size:]\n",
    "y_volatility_test = y_volatility[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([242, 16]) torch.Size([242]) torch.Size([242]) torch.Size([242])\n",
      "torch.Size([965, 16]) torch.Size([965]) torch.Size([965]) torch.Size([965])\n",
      "tensor([0.0102, 0.0120, 0.0093, 0.0097, 0.3495, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.7970, 0.5885, 0.5397, 0.0000, 0.0011, 0.5185, 0.4971]) tensor(0.0050) tensor(0) tensor(nan)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, y_price_test.shape, y_direction_test.shape, y_volatility_test.shape)\n",
    "print(X_train.shape, y_price_train.shape, y_direction_train.shape, y_volatility_train.shape)\n",
    "print(X_train[0], y_price_train[0], y_direction_train[0], y_volatility_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: nan\n",
      "Epoch [20/50], Loss: nan\n",
      "Epoch [30/50], Loss: nan\n",
      "Epoch [40/50], Loss: nan\n",
      "Epoch [50/50], Loss: nan\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "# Create DataLoader for training\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Ensure X_train and X_test have the correct shape [batch_size, sequence_length, feature_dim]\n",
    "X_train = X_train.unsqueeze(1) if len(X_train.shape) == 2 else X_train\n",
    "X_test = X_test.unsqueeze(1) if len(X_test.shape) == 2 else X_test\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_price_train, y_direction_train, y_volatility_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_price_test, y_direction_test, y_volatility_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize model\n",
    "market_dim = X_train.shape[2] if len(X_train.shape) > 2 else 1\n",
    "model = AdvancedLSTMPredictor(\n",
    "    market_dim=market_dim,\n",
    "    hidden_dim=50,\n",
    "    num_layers=2,\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "# Training parameters\n",
    "criterion = CustomLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "num_epochs = 50\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_market, batch_y_price, batch_y_dir, batch_y_vol in train_loader:\n",
    "        # Move data to device\n",
    "        batch_market = batch_market.to(device)\n",
    "        batch_y_price = batch_y_price.to(device)\n",
    "        batch_y_dir = batch_y_dir.to(device)\n",
    "        batch_y_vol = batch_y_vol.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        price_pred, direction_pred, volatility_pred = model(batch_market)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(\n",
    "            (price_pred, direction_pred, volatility_pred),\n",
    "            (batch_y_price, batch_y_dir, batch_y_vol)\n",
    "        )\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
